CONTEXT7_API_KEY=ctx7sk-your-key-here
GITHUB_TOKEN=ghp_your-token-here

# curl https://api.synthetic.new/openai/v1/models -H "Authorization: Bearer ${SYNTHETIC_API_KEY}"
# ----------------------------------------
# ID: hf:zai-org/GLM-4.7
# Input Modalities: text
# Output Modalities: text
# Context Length: 202752
# Max Output Length: 65536
# Supported Sampling Parameters: temperature, top_k, top_p, repetition_penalty, frequency_penalty, presence_penalty, stop, seed
# Supported Features: tools, json_mode, structured_outputs, reasoning
# ----------------------------------------
# ID: hf:deepseek-ai/DeepSeek-V3.2
# Input Modalities: text
# Output Modalities: text
# Context Length: 162816
# Supported Sampling Parameters: temperature, top_k, top_p, repetition_penalty, frequency_penalty, presence_penalty, stop, seed
# Supported Features: tools, json_mode, structured_outputs, reasoning
# ----------------------------------------
# ID: hf:nvidia/Kimi-K2.5-NVFP4
# Input Modalities: text, image
# Output Modalities: text
# Context Length: 262144
# Max Output Length: 65536
# Supported Sampling Parameters: temperature, top_k, top_p, repetition_penalty, frequency_penalty, presence_penalty, stop, seed
# Supported Features: tools, json_mode, structured_outputs, reasoning
# ----------------------------------------
# ID: hf:MiniMaxAI/MiniMax-M2.1
# Input Modalities: text
# Output Modalities: text
# Context Length: 196608
# Supported Sampling Parameters: temperature, top_k, top_p, repetition_penalty, frequency_penalty, presence_penalty, stop, seed
# Supported Features: tools, json_mode, structured_outputs, reasoning
# ----------------------------------------
# ID: hf:Qwen/Qwen3-Coder-480B-A35B-Instruct
# Input Modalities: text
# Output Modalities: text
# Context Length: 262144
# Supported Sampling Parameters: temperature, top_k, top_p, repetition_penalty, frequency_penalty, presence_penalty, stop, seed
# Supported Features: tools, json_mode, structured_outputs, reasoning
SYNTHETIC_OPENAI_COMPATIBLE_MODELS="synthetic/hf:MiniMaxAI/MiniMax-M2.1 /
    synthetic/hf:Qwen/Qwen3-Coder-480B-A35B-Instruct /
    synthetic/hf:deepseek-ai/DeepSeek-V3.2 /
    synthetic/hf:nvidia/Kimi-K2.5-NVFP4 /
    synthetic/hf:zai-org/GLM-4.7"

PEEKABOO_AI_PROVIDERS=synthetic/hf:nvidia/Kimi-K2.5-NVFP4 # peekaboo needs image capability, and Synthetic has Kimi K2.5 for that
